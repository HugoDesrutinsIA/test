# -*- coding: utf-8 -*-
"""Detection_Anomalie_auto_encodeur

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mxdV00vysidoYShKGsJRQkkAAZhrie9x

Réalisé par Hugo Desrutins , Stagiaire fiabilité EDF , ce document est restreint à l'utilisation pour l'entreprise EDF uniquement, toutes reproductions est interdite et passible d'une amende.

Ce Notebook permet la détection d'anomalie sur des données vibratoires par l'utilisation d'un réseau de neurones de type Auto-encodeur. Le principe est de détecter un comportement anormal sur le comportement vibratoire d'une machine. Ce modèle n'a pas vocation à diagnostiquer ou à classer le défaut mais sert simplement d'indicateur sur le comportement du système

Installation des librairies
"""

if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-xu/6/R")
install.packages("googledrive")
library("googledrive")

if (file.exists("/usr/local/lib/python3.6/dist-packages/google/colab_ipython.py")){
  install.packages("R.utils")
  library("R.utils")
  library("httr")
  my_check <- function() {return(TRUE)}
  reassignInPackage("is_interactive", pkgName = "httr", my_check)
  options(rlang_interactive=TRUE)
}

options(warn=-1)

# load libraries
library(dplyr)
library(h2o)
library(RCurl)

getwd() #Repère notre dossier de travail

#Url des fichiers CSV servant de base de données pour notre réseau
x1  = getURL("https://raw.githubusercontent.com/HugoDesrutinsIA/test/main/testtest4.csv") # jeu de données sain (01/07/2021 - 25/07/2021)
#x2  = getURL("https://raw.githubusercontent.com/HugoDesrutinsIA/test/main/testtest4.csv") 
x3  = getURL("https://raw.githubusercontent.com/HugoDesrutinsIA/test/main/testanomal6.csv") # Test (08/08/2021)
#x4  = getURL("https://raw.githubusercontent.com/HugoDesrutinsIA/test/main/testanomal6.csv") 

ref1 = read.csv(text = x1, sep=",", header =T)
#ref2 = read.csv(text = x2, sep=",", header =T)
crise1 = read.csv(text = x3, sep=",", header =T)
#crise2 = read.csv(text = x4, sep=",", header =T)

#Résumé de nos données (moyenne , ecart type, min/max etc...)
summary(ref1)
#summary(ref2)
summary(crise1)
#summary(crise2)

"""On extrait uniquement les données utiles de notre jeu de données, ceci nous permet de diminuer le volume de notre jeu de données et de conserver uniquement ce qu'on apelle les features, qui représentent les paramètres utiles de notre jeu de données. """

ref1$group = as.factor(round(ref1$time))
#ref2$group = as.factor(round(ref2$time))
crise1$group = as.factor(round(crise1$time))
#crise2$group = as.factor(round(crise2$time))

files = list(ref1,crise1)

features = NULL
for (i in 1:2){
res = files[[i]] %>%
    group_by(group) %>%
    summarize(mv_mean = mean(mv),
              mv_sd = sd(mv),
              mv_min = min(mv),
              mv_max = max(mv),
              mv_median = median(mv)
              # ay_mean = mean(ay),
              # ay_sd = sd(ay),
              # ay_min = min(ay),
              # ay_may = max(ay),
              # ay_median = median(ay),
              # az_mean = mean(az),
              # az_sd = sd(az),
              # az_min = min(az),
              # az_maz = max(az),
              # az_median = median(az),
              # aT_mean = mean(aT),
              # aT_sd = sd(aT),
              # aT_min = min(aT),
              # aT_maT = max(aT),
              # aT_median = median(aT)
             )
    features = rbind(features, res)
}

#Visualisation des features
unclass(res)

"""On initialise la librairie H2o et on sépare notre jeu de données en 2 parties : Données d'entrainement et Données Test."""

h2o.init()
train_data = features[1:(nrow(features)/2),2:ncol(features)]
test_data = features[(nrow(features)/2):nrow(features),2:ncol(features)]

# Séparation donnée de test et donnée d'entrainement
train_h2o = as.h2o(train_data)
test_h2o = as.h2o(test_data)

unclass(train_data)
unclass(test_data)

"""On entraine notre modèle"""

model_anomaly = h2o.deeplearning(x = 2:ncol(features)
                 , training_frame = train_h2o
                 , model_id = "Anomaly1"
                 , autoencoder = TRUE
                 , ignore_const_cols = FALSE
                 , hidden = c(100,100,50,100,100)
                 , epochs = 100
                 , activation ="Tanh")

model_anomaly
summary(model_anomaly)
perf <- h2o.performance(model_anomaly)

"""On calcule ensuite le score d'anomalie"""

train_anomaly = h2o.anomaly(model_anomaly
                      , train_h2o
                      , per_feature = FALSE) %>% as.data.frame()
# Crée un label pour les données saines
train_anomaly$y = 0

# Visualisation de nos données
head(train_anomaly)

"""Le score d'anomalie à 0 est la preuve que notre modèle a bien été entrainé. En effet avant de calculer ce score d'anomalie on a entrainé notre réseau sur les données d'entrainement. Il est donc logique que le score d'anomalie sur ces données soit nulles. """

threshold = quantile(train_anomaly$Reconstruction.MSE, probs = 0.999)
test_anomaly = h2o.anomaly(model_anomaly
                      , test_h2o
                      , per_feature = FALSE) %>% as.data.frame()

# Crée un label pour les données saines
test_anomaly$y = 1

results = data.frame(rbind(train_anomaly,test_anomaly), threshold)
head(results)

# Adjust plot sizes
options(repr.plot.width = 15, repr.plot.height = 6)
plot(results$Reconstruction.MSE, type = 'n', xlab='observations', ylab='Reconstruction.MSE', main = "Résultat détection d'anomalie")
points(results$Reconstruction.MSE, pch=19, col=ifelse(results$Reconstruction.MSE < threshold, "green", "orange"))
abline(h=threshold, col='red', lwd=3)

"""Comment interpréter ces résultats ? 

Le concept de la détection d'anomalie avec un modèle d'auto-encodeur est simple. On entraine notre modèle avec des données "saines" et on place ensuite en entrée de nouveaux jeux de données.

Le paramètre MSE (Mean square error) nous permet de détecter les différences entre les deux jeux de données et ici de détecter facilement un comportement anormal sur notre système. 

L'exemple qui est utilisé dans ce code est assez parlant on a placé en jeux de données de référence des données "saines" de notre système. Le 1er jeu de données (Observation 110 à 175) a un MSE très faible signifiant que notre système a un comportement similaire à notre référence. 

Cependant les deux jeux de données suivants (Observations 175 à 300+) contiennent un balourds marqué. On observe alors facilement un paramètre MSE qui s'accroit au fil des observations. On peut donc facilement déduire une anomalie sur notre système. 

On a ici aucune info sur la nature de l'anomalie , on constate simplement qu'il y en a une. 


"""